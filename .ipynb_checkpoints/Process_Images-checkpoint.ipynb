{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import math\n",
    "import utm\n",
    "import time\n",
    "\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "from shapely.geometry import shape, mapping\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from bokeh.plotting import ColumnDataSource\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from bokeh.palettes import Spectral3\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "from radar_scrape import get_radar_img_urls, request_img_files\n",
    "from get_station_data import get_daily_runoff\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "DB_DIR = os.path.join(BASE_DIR, 'code/hydat_db')\n",
    "PROJECT_DIR = os.path.abspath('')\n",
    "RADAR_IMG_DIR = os.path.join(PROJECT_DIR, 'data/masked_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(DB_DIR + '/WSC_Stations_Master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim of cmap array =  (196, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "# first, create a dictionary for mapping radar precip colors to mm/hr rates\n",
    "cbar_path = os.path.join(PROJECT_DIR, 'img')\n",
    "radar_cmap_img = Image.open(os.path.join(cbar_path, 'colorbar.png')).convert('RGB')\n",
    "cmap_array = np.asarray(radar_cmap_img).astype(np.uint8)  \n",
    "print('dim of cmap array = ', cmap_array.shape)\n",
    "c_width, c_height = 20, 14\n",
    "\n",
    "colour_map_dict = {}\n",
    "intensities = [0.1, 1, 2, 4, 8, 12, 16, 24, 36, 50, 75, 100, 150, 200][::-1]\n",
    "for n in range(14):\n",
    "    this_color = cmap_array[n * 14:n * 14 + 14, :, :][0,0,:]\n",
    "    colour_map_dict[str(list(this_color))] = intensities[n]\n",
    "    \n",
    "# add an entry for zero or null\n",
    "colour_map_dict[str(list([150, 150, 150]))] = 0\n",
    "colour_map_dict[str(list([0, 0, 0]))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['[102, 0, 153]', '[153, 51, 204]', '[255, 2, 153]', '[255, 0, 0]', '[255, 102, 0]', '[255, 153, 0]', '[255, 204, 0]', '[255, 255, 51]', '[0, 102, 0]', '[0, 153, 0]', '[0, 204, 0]', '[0, 255, 102]', '[0, 153, 255]', '[153, 204, 255]', '[150, 150, 150]', '[0, 0, 0]'])\n"
     ]
    }
   ],
   "source": [
    "print(colour_map_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = os.listdir(RADAR_IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the files and format\n",
    "# the filenames as timestamps\n",
    "def convert_str_to_datetime(s):\n",
    "    s = s.values[0]\n",
    "    return pd.to_datetime(s[:4] + '-' + s[4:6] + '-' + s[6:8] + ' ' + s[8:10] + ':' + s[10:12] )\n",
    "\n",
    "\n",
    "event_dict = {}\n",
    "for stn in stations:\n",
    "    dates_df = pd.DataFrame()\n",
    "    event_dict[stn] = {}\n",
    "    images = os.listdir(os.path.join(RADAR_IMG_DIR, stn))\n",
    "    dates_df['dt_strings'] = [e.split('_')[0] for e in images]\n",
    "    dates_df['datetime'] = dates_df.apply(lambda x: convert_str_to_datetime(x), axis=1)\n",
    "    dates_df = dates_df.sort_values(by='datetime')\n",
    "    dates_df['dt_hours'] = dates_df['datetime'].diff(1).astype('timedelta64[h]')\n",
    "    dates_df.reset_index(inplace=True, drop=True)\n",
    "    break_ixs = dates_df[dates_df['dt_hours'] > 24].index\n",
    "    last_ix = 0\n",
    "    n = 0\n",
    "    for ix in range(1, len(break_ixs)):\n",
    "        dt_strings_array = dates_df.loc[break_ixs[ix - 1]:break_ixs[ix] - 1, 'dt_strings'].to_numpy()\n",
    "        event_dict[stn][n] = dt_strings_array\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_image(datetime_string, stn):\n",
    "    folder_path = os.path.join(RADAR_IMG_DIR, stn)\n",
    "    cropped_radar_img = Image.open(os.path.join(folder_path, str(datetime_string) + '_crp.gif')).convert('RGB')\n",
    "    return np.asarray(cropped_radar_img).astype(np.uint8)\n",
    "\n",
    "def convert_pixel_color_to_precip_volume(row, stn):\n",
    "    datetime_string = row['time_string']\n",
    "    duration = row['dt']\n",
    "    img_array = retrieve_image(datetime_string, stn)\n",
    "    rows = img_array.shape[0]\n",
    "    cols = img_array.shape[1]\n",
    "    vol_array = np.zeros((rows, cols, 1))\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            map_color = str(list(img_array[r, c]))\n",
    "            if map_color in list(colour_map_dict.keys()):\n",
    "                # convert mm/h to m^3\n",
    "                total_vol = colour_map_dict[map_color] * duration * 1000**2 / 1000\n",
    "                vol_array[r, c] = total_vol\n",
    "            else:\n",
    "                vol_array[r, c] = 0\n",
    "    return vol_array.flatten().sum()\n",
    "\n",
    "\n",
    "def construct_unit_hydrograph(stn, event_timestamps):\n",
    "    event_df = pd.DataFrame()\n",
    "    event_df['time_string'] = event_timestamps\n",
    "    event_df['datetime'] = event_df.apply(lambda x: convert_str_to_datetime(x), axis=1)\n",
    "    event_df['dt'] = event_df['datetime'].diff(-1).astype('timedelta64[h]') * -1\n",
    "    event_df['precip_vol'] = event_df.apply(lambda row: convert_pixel_color_to_precip_volume(row, stn), axis=1)\n",
    "    return event_df\n",
    "\n",
    "def concatenate_precip_and_flow(stn, event):\n",
    "    precip_df = construct_unit_hydrograph(stn, event)\n",
    "    precip_df.set_index('datetime', inplace=True)\n",
    "    precip_df = precip_df.resample('1D').sum()\n",
    "    \n",
    "    precip_df['cumsum_m3'] = precip_df['precip_vol'].cumsum()\n",
    "    precip_df['precip_rate_cms'] = precip_df['precip_vol'] / 24 / 3600\n",
    "    \n",
    "    ## find the concurrent flow record\n",
    "    flow_df = get_daily_runoff(test_stn)\n",
    "    flow_df.rename(columns={'DAILY_FLOW': 'flow_cms'}, inplace=True)\n",
    "    flow_df['Year'] = flow_df.index.year\n",
    "    flow_df['Month'] = flow_df.index.month\n",
    "    \n",
    "    df = pd.concat([precip_df, flow_df[['flow_cms']]], join='inner', axis=1)\n",
    "    df = df[['precip_rate_cms', 'flow_cms']]\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08NN019\n"
     ]
    }
   ],
   "source": [
    "test_stn = stations[1]\n",
    "test_event = event_dict[test_stn][0]\n",
    "df = concatenate_precip_and_flow(test_stn, test_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-93bdb1439711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_stn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_events\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "plots = []\n",
    "\n",
    "n_events = len(event_dict[test_stn])\n",
    "print(n_events)\n",
    "print(asdf)\n",
    "\n",
    "for i in np.arange(0, len(new_events) - 1, 2):\n",
    "    \n",
    "    # parse a single event pair\n",
    "    this_event = new_events.iloc[i:i+2]\n",
    "    \n",
    "    s1 = figure(background_fill_color=\"#fafafa\", x_axis_type='datetime')\n",
    "    \n",
    "    s1.circle(this_event.index, this_event['Q'], \n",
    "              size=12, alpha=0.8, color=\"red\")#, legend_label='{estimated endpoints}')\n",
    "    s1.xaxis.major_label_orientation = math.pi/2\n",
    "    this_start = pd.to_datetime(this_event.index.values[0])\n",
    "    this_end = pd.to_datetime(this_event.index.values[1])\n",
    "    this_dat = lag_df[(lag_df.index >= this_start) & (lag_df.index <= this_end)][['Q']]\n",
    "        \n",
    "    year = this_event.index.year.values[0]\n",
    "    month = this_event.index.month.values[0]\n",
    "    day = this_event.index.day.values[0]\n",
    "    date = '{}-{}-{}'.format(year, month, day)\n",
    "    s1.line(this_dat.index, this_dat['Q'], color='blue')\n",
    "    \n",
    "    start_month = this_start.month\n",
    "    \n",
    "    # only add plot if the event is in summer\n",
    "    if (start_month > 5) & (start_month < 11):\n",
    "        plots.append(s1)\n",
    "print('there are {} plots'.format(len(plots)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(df.index, df['precip_rate_cms'], label='precip vol [m^3/s]')\n",
    "ax.plot(df.index, df['flow_cms'], label='precip vol [m^3/s]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
