{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import math\n",
    "import utm\n",
    "import time\n",
    "\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "from shapely.geometry import shape, mapping\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show, output_notebook\n",
    "from bokeh.plotting import ColumnDataSource\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from bokeh.palettes import Spectral3\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "from radar_scrape import get_radar_img_urls, request_img_files\n",
    "from get_station_data import get_daily_runoff\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "DB_DIR = os.path.join(BASE_DIR, 'code/hydat_db')\n",
    "PROJECT_DIR = os.path.abspath('')\n",
    "RADAR_IMG_DIR = os.path.join(PROJECT_DIR, 'sorted_radar_images')\n",
    "CROPPED_IMG_DIR = os.path.join(PROJECT_DIR, 'data/masked_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(DB_DIR + '/WSC_Stations_Master.csv')\n",
    "\n",
    "# list the stations whose catchments fall off the edge of the map\n",
    "incomplete_stns = pd.read_csv(os.path.join(PROJECT_DIR,'data/incomplete_sites.txt')).columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a dictionary for mapping radar precip colors to mm/hr rates\n",
    "cbar_path = os.path.join(PROJECT_DIR, 'img')\n",
    "radar_cmap_img = Image.open(os.path.join(cbar_path, 'colorbar.png')).convert('RGB')\n",
    "cmap_array = np.asarray(radar_cmap_img).astype(np.uint8)  \n",
    "print('dim of cmap array = ', cmap_array.shape)\n",
    "c_width, c_height = 20, 14\n",
    "\n",
    "colour_map_dict = {}\n",
    "intensities = [0.1, 1., 2., 4., 8., 12., 16., 24., 36., 50., 75., 100., 150., 200.][::-1]\n",
    "for n in range(14):\n",
    "    this_color = cmap_array[n * 14:n * 14 + 14, :][0,0,:]\n",
    "    colour_map_dict[str(list(this_color))] = float(intensities[n])\n",
    "    \n",
    "# add an entry for zero or null\n",
    "colour_map_dict[str(list([150, 150, 150]))] = 0.\n",
    "colour_map_dict[str(list([0, 0, 0]))] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = os.listdir(CROPPED_IMG_DIR)\n",
    "\n",
    "for stn in stations:\n",
    "    folder_path = os.path.join(CROPPED_IMG_DIR, stn)\n",
    "    if len(os.listdir(folder_path)) == 0:\n",
    "#         print('empty: ', stn)\n",
    "        os.rmdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = os.listdir(CROPPED_IMG_DIR)\n",
    "\n",
    "# iterate through the files and format\n",
    "# the filenames as timestamps\n",
    "def convert_str_to_datetime(s):\n",
    "    s = s.values[0]\n",
    "    return pd.to_datetime(s[:4] + '-' + s[4:6] + '-' + s[6:8] + ' ' + s[8:10] + ':' + s[10:12] )\n",
    "\n",
    "\n",
    "event_dict = {}\n",
    "for stn in stations:\n",
    "    dates_df = pd.DataFrame()\n",
    "    event_dict[stn] = {}\n",
    "    images = os.listdir(os.path.join(CROPPED_IMG_DIR, stn))\n",
    "    dates_df['dt_strings'] = [e.split('_')[0] for e in images]\n",
    "    dates_df['datetime'] = dates_df.apply(lambda x: convert_str_to_datetime(x), axis=1)\n",
    "    dates_df = dates_df.sort_values(by='datetime')\n",
    "    dates_df['dt_hours'] = dates_df['datetime'].diff(1).astype('timedelta64[h]')\n",
    "    dates_df.reset_index(inplace=True, drop=True)\n",
    "    break_ixs = dates_df[dates_df['dt_hours'] > 24].index\n",
    "    last_ix = 0\n",
    "    n = 0\n",
    "    for ix in range(1, len(break_ixs)):\n",
    "        dt_strings_array = dates_df.loc[break_ixs[ix - 1]:break_ixs[ix] - 1, 'dt_strings'].to_numpy()\n",
    "        event_dict[stn][n] = dt_strings_array\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_image(datetime_string, stn):\n",
    "    folder_path = os.path.join(CROPPED_IMG_DIR, stn)\n",
    "    cropped_radar_img = Image.open(os.path.join(folder_path, str(datetime_string) + '_crp.gif')).convert('RGB')\n",
    "#     print(np.asarray(cropped_radar_img).astype(np.uint8)[0][0])\n",
    "    return np.asarray(cropped_radar_img).astype(np.uint8)\n",
    "\n",
    "def convert_pixel_color_to_precip_volume(row, stn):\n",
    "    datetime_string = row['time_string']\n",
    "    duration = row['dt']\n",
    "    img_array = retrieve_image(datetime_string, stn)\n",
    "    rows = img_array.shape[0]\n",
    "    cols = img_array.shape[1]\n",
    "    vol_array = np.zeros((rows, cols, 1))\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            map_color = str(list(img_array[r, c]))\n",
    "            if map_color in list(colour_map_dict.keys()):\n",
    "                # convert mm/h to m^3\n",
    "                total_vol = colour_map_dict[map_color] * duration * 1000**2 / 1000\n",
    "                vol_array[r, c] = total_vol\n",
    "            else:\n",
    "                vol_array[r, c] = 0\n",
    "    return vol_array.flatten().sum()\n",
    "\n",
    "\n",
    "def construct_unit_hydrograph(stn, event_timestamps):\n",
    "    event_df = pd.DataFrame()\n",
    "    event_df['time_string'] = event_timestamps\n",
    "    event_df['datetime'] = event_df.apply(lambda x: convert_str_to_datetime(x), axis=1)\n",
    "    event_df['dt'] = event_df['datetime'].diff(-1).astype('timedelta64[h]') * -1\n",
    "    event_df['precip_vol'] = event_df.apply(lambda row: convert_pixel_color_to_precip_volume(row, stn), axis=1)\n",
    "    return event_df\n",
    "\n",
    "def concatenate_precip_and_flow(stn, event):\n",
    "    precip_df = construct_unit_hydrograph(stn, event)\n",
    "    precip_df.set_index('datetime', inplace=True)\n",
    "    precip_df = precip_df.resample('1D').sum()\n",
    "    \n",
    "    precip_df['cumsum_m3'] = precip_df['precip_vol'].cumsum()\n",
    "    precip_df['precip_rate_cms'] = precip_df['precip_vol'] / 24 / 3600\n",
    "    \n",
    "    ## find the concurrent flow record\n",
    "    flow_df = get_daily_runoff(stn)\n",
    "    flow_df.rename(columns={'DAILY_FLOW': 'flow_cms'}, inplace=True)\n",
    "    flow_df['Year'] = flow_df.index.year\n",
    "    flow_df['Month'] = flow_df.index.month\n",
    "    \n",
    "    df = pd.concat([precip_df, flow_df[['flow_cms']]], join='inner', axis=1)\n",
    "    df = df[['precip_rate_cms', 'flow_cms']]\n",
    "    event_duration = (df.index[-1] - df.index[0]).days\n",
    "    if event_duration >= 2:\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def create_plot_grid(stn):\n",
    "    \n",
    "    n_events = len(event_dict[stn])\n",
    "    \n",
    "    plots = []    \n",
    "    for event in event_dict[stn]:\n",
    "        # parse a single event pair\n",
    "        this_event_df = concatenate_precip_and_flow(stn, event_dict[stn][event])\n",
    "        if this_event_df is not None:\n",
    "            s1 = figure(background_fill_color=\"#fafafa\", x_axis_type='datetime')  \n",
    "            s1.xaxis.major_label_orientation = math.pi/2\n",
    "            s1.line(this_event_df.index, this_event_df['precip_rate_cms'], color='green')\n",
    "            s1.line(this_event_df.index, this_event_df['flow_cms'], color='blue')\n",
    "            plots.append(s1)    \n",
    "    return plots\n",
    "\n",
    "def arrange_plots_into_grid(stn_plots):\n",
    "    stn = stn_plots[0]\n",
    "    plots = stn_plots[1]\n",
    "    stn_info = stations_df[stations_df['Station Number'] == stn]\n",
    "    stn_DA = stn_info['Gross Drainage Area (km2)'].values[0]\n",
    "    print('Station: {} ({} km^2)'.format(stn, stn_DA))\n",
    "    n_cols = 5\n",
    "    n_rows = int(np.ceil(len(plots) / n_cols))\n",
    "\n",
    "    g = []\n",
    "    for i in range(0, len(plots), n_cols):\n",
    "        g += [plots[i:i+n_cols]]\n",
    "    grid = gridplot(g, plot_width=150, plot_height=150)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Game -- Create 2d histogram plots to show where rain falls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def convert_pixel_color_to_precip_count(row, stn):\n",
    "    datetime_string = row['time_string']\n",
    "    duration = row['dt']\n",
    "    if np.isnan(row['dt']):\n",
    "        duration = 1\n",
    "    img_array = retrieve_image(datetime_string, stn)\n",
    "    rows = img_array.shape[0]\n",
    "    cols = img_array.shape[1]\n",
    "    count = np.zeros((rows, cols))\n",
    "    precip_colors = [e for e in list(colour_map_dict.keys()) if e != '[0, 0, 0]']\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            map_color = str(list(img_array[r, c]))\n",
    "            if map_color in precip_colors:\n",
    "                # convert mm/h to m^3\n",
    "                weighted_count = float(colour_map_dict[map_color]) * duration\n",
    "                count[r, c] = weighted_count \n",
    "\n",
    "    return count \n",
    "\n",
    "def colorize_precip_frequency(data):\n",
    "    recolored_matrix = np.zeros((data.shape[0], data.shape[1], 4))\n",
    "    rows = data.shape[0]\n",
    "    cols = data.shape[1]\n",
    "    colour_map = plt.cm.viridis[::-1]\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            recolored_matrix[r, c] = colour_map(data[r, c])\n",
    "    return Image.fromarray(recolored_matrix, 'RGB')\n",
    "\n",
    "def construct_precip_histogram(stn):\n",
    "    initialized = False\n",
    "    events = event_dict[stn]\n",
    "    for e in events:\n",
    "        event_df = pd.DataFrame()\n",
    "        event_df['time_string'] = events[e]\n",
    "        event_df['datetime'] = event_df.apply(lambda x: convert_str_to_datetime(x), axis=1)\n",
    "        event_df['dt'] = event_df['datetime'].diff(-1).astype('timedelta64[h]') * -1\n",
    "\n",
    "        for index, row in event_df.iterrows():\n",
    "            if initialized == False:\n",
    "                count_array = convert_pixel_color_to_precip_count(row, stn)\n",
    "                initialized = True\n",
    "            else:\n",
    "                new_count = convert_pixel_color_to_precip_count(row, stn)\n",
    "                if new_count.size == count_array.size:\n",
    "                    count_array = np.add(count_array, new_count)\n",
    "                else:\n",
    "                    row_diff = count_array.shape[0] - new_count.shape[0]\n",
    "                    col_diff = count_array.shape[1] - new_count.shape[1]\n",
    "                    if row_diff > 0:\n",
    "                        new_count.append(np.zeros(count_array.shape[1], 1))\n",
    "                        count_array = np.add(count_array, new_count)\n",
    "    \n",
    "    normalized_array = normalize(count_array)\n",
    "#     recolored_img = colorize_precip_frequency(normalized_array)\n",
    "    return normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_img(stn):\n",
    "    event = event_dict[stn][0]\n",
    "    precip_in_frame = False\n",
    "    map_colors = [e for e in list(colour_map_dict.keys()) if e != '[0, 0, 0]']\n",
    "    min_paint = 1E12\n",
    "    for e in event:\n",
    "        img_array = retrieve_image(e, stn)\n",
    "        rows = img_array.shape[0]\n",
    "        cols = img_array.shape[1]\n",
    "        n_colors = 0\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                map_color = str(list(img_array[r, c]))\n",
    "                if map_color in map_colors:\n",
    "                    precip_in_frame = True\n",
    "                    n_colors += 1\n",
    "                elif map_color == '[0, 0, 0]':\n",
    "                    img_array[r, c] = np.asarray([0, 0, 0])\n",
    "        if n_colors < min_paint:\n",
    "            min_paint = n_colors\n",
    "            best_img_event = e\n",
    "                    \n",
    "        if precip_in_frame == False:\n",
    "#             print(img_array.shape)\n",
    "            return Image.fromarray(img_array, 'RGB')\n",
    "        else:\n",
    "            return Image.fromarray(retrieve_image(best_img_event, stn))\n",
    "\n",
    "@jit\n",
    "def reset_bg_colors(base_img_array, new_img):\n",
    "    rows = base_img_array.shape[0]\n",
    "    cols = base_img_array.shape[1]\n",
    "    for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                base_color = base_img_array[r, c]\n",
    "#                 print(base_color, type(base_color))\n",
    "                if (base_color == np.zeros(3)).all():\n",
    "                    new_img[r, c] = np.nan\n",
    "    return new_img\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = os.listdir(CROPPED_IMG_DIR)\n",
    "\n",
    "station_data = stations_df[stations_df['Station Number'].isin(stations)]\n",
    "station_data = station_data.sort_values('Gross Drainage Area (km2)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11, 11, figsize=(26, 20))\n",
    "\n",
    "colored_maps = []\n",
    "rows = 10\n",
    "cols = 11\n",
    "n = 0\n",
    "r, c = 0, 0\n",
    "\n",
    "stations = [e for e in station_data['Station Number'].values if e not in incomplete_stns]\n",
    "    \n",
    "for n in range(len(stations)):\n",
    "    stn = stations[n]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    base_image = get_sample_img(stn)   \n",
    "    stn_dat = stations_df[stations_df['Station Number'] == stn]\n",
    "    stn_da = stn_dat['Gross Drainage Area (km2)']\n",
    "#     ax[r, c].imshow(base_image, alpha=0.5)\n",
    "    colorized_img_array = construct_precip_histogram(stn)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print('{} ({}/{}) process time: {:.2f} s'.format(stn, n, len(stations),t1-t0))\n",
    "    base_img_array = np.array(base_image, dtype=np.int_)\n",
    "    remapped_colors_array = reset_bg_colors(base_img_array, colorized_img_array)\n",
    "    ax[r, c].imshow(remapped_colors_array, cmap='viridis_r', interpolation='nearest', alpha=1)\n",
    "    \n",
    "    ax[r, c].axis('off')\n",
    "    ax[r, c].set_title(stn + ': {:.1f} km^2'.format(stn_da.values[0]))\n",
    "    c += 1\n",
    "    if c == 11:\n",
    "        c = 0\n",
    "        r += 1\n",
    "\n",
    "    n += 1\n",
    "\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Hydrograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = []\n",
    "n = 0\n",
    "# stations_1 = stations[:5]\n",
    "for stn in ['08MH147']:\n",
    "    print(stn)\n",
    "    print('{} ({}/{})'.format(stn, n, len(stations)))\n",
    "    grids.append((stn, create_plot_grid(stn)))\n",
    "    n += 1\n",
    "    \n",
    "show(arrange_plots_into_grid(grids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
