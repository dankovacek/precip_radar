{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Query the HYDAT database for runoff events in BC and Alberta that fall within 175km of a radar station in Western Canada.  \n",
    "\n",
    "Filter for watersheds with data after June 2007.  \n",
    "\n",
    "Filter for watersheds larger than 15 km^2 and smaller than 500 km^2.\n",
    "\n",
    "Output table like:\n",
    "\n",
    "| Station | ID | Drainage Area [$km^2$] | Start Date | End Date |\n",
    "|---|---|---|---|---|\n",
    "| Elaho | EHBN008 | 400 | 2007 | 2017 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import math\n",
    "import utm\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import itertools\n",
    "import fiona\n",
    "from geopy import distance\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from shapely.geometry import shape, mapping\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from bokeh.plotting import ColumnDataSource, output_notebook\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from bokeh.palettes import Spectral3\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()\n",
    "\n",
    "from radar_scrape import get_radar_img_urls, request_img_files\n",
    "from get_station_data import get_daily_runoff\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.layers.core import Dense \n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "DB_DIR = os.path.join(BASE_DIR, 'code/hydat_db')\n",
    "PROJECT_DIR = os.path.abspath('')\n",
    "IMG_DIR = os.path.join(PROJECT_DIR, 'data/radar_img')\n",
    "RADAR_IMG_DIR = os.path.join(PROJECT_DIR, 'data/sorted_radar_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define radar sites\n",
    "radar_stations = {'CASAG': {'lat_lon': [49.0580516, -122.470667], # radar location code, lat/lon\n",
    "                       'scale': 1,\n",
    "                      'alt_name': 'Aldergrove',\n",
    "                        }, # km/pixel                       \n",
    "               'CASPG': {'lat_lon': [53.916943, -122.749443], # radar location code, lat/lon\n",
    "                       'scale': 1,\n",
    "                      'alt_name': 'Prince George',}, # km/pixel}, # km/pixel\n",
    "               'CASSS': {'lat_lon': [50.271790, -119.276505], # radar location code, lat/lon\n",
    "                       'scale': 1,\n",
    "                      'alt_name': 'Silver Star',}, # km/pixel}, # km/pixel\n",
    "               'CASSI': {'lat_lon': [48.407326, -123.329773], # radar location code, lat/lon\n",
    "                       'scale': 1,\n",
    "                      'alt_name': 'Victoria',}, # km/pixel}, # km/pixel\n",
    "               'CASSM': {'lat_lon': [51.206092, -113.399426],\n",
    "                        'scale': 1,\n",
    "                        'alt_name': 'Strathmore'},\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_radar_stn(row):\n",
    "    \"\"\" \n",
    "    Input the dict of all station distances,\n",
    "    Return the location code of the nearest radar station.\n",
    "    \"\"\"\n",
    "    radar_station_distances = row['radar_stn_distance_dict']\n",
    "    min_dist = min(radar_station_distances.items(), key=lambda x: x[1])\n",
    "    return min_dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_radar_stn_distance(row):\n",
    "    \"\"\" \n",
    "    Input the dict of all station distances,\n",
    "    Return the location code of the nearest radar station.\n",
    "    \"\"\"\n",
    "    radar_station_distances = row['radar_stn_distance_dict']\n",
    "    min_dist = min(radar_station_distances.items(), key=lambda x: x[1])\n",
    "    return min_dist[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(wsc_row, radar_station):\n",
    "    wsc_stn_coords = (wsc_row['Latitude'], wsc_row['Longitude'])\n",
    "    radar_coords = radar_stations[radar_station]['lat_lon']\n",
    "    return distance.distance(radar_coords, wsc_stn_coords).km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_radar_stn_distances(row):\n",
    "    distance_dict = {}\n",
    "    for site in radar_stations:\n",
    "        distance_dict[site] = calc_distance(row, site)\n",
    "    return distance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_wsc_station_info_dataframe():\n",
    "    # import master station list\n",
    "    stations_df = pd.read_csv(DB_DIR + '/WSC_Stations_Master.csv')\n",
    "    # filter for stations that have concurrent record with the historical radar record\n",
    "    stations_df['RADAR_Overlap'] = stations_df['Year To'].astype(int) - 2007\n",
    "    stations_filtered = stations_df[stations_df['RADAR_Overlap'] > 0]\n",
    "    # filter for stations that are natural flow regimes\n",
    "    stations_filtered = stations_filtered[stations_filtered['Regulation'] == 'N']\n",
    "    stations_filtered.rename(columns={'Gross Drainage Area (km2)': 'DA'}, inplace=True)\n",
    "    # filter for stations in Alberta and British Columbia\n",
    "    stations_filtered = stations_filtered[(stations_filtered['Province'] == 'BC') | (stations_filtered['Province'] == 'AB')]\n",
    "    \n",
    "    # calculate distance to each radar station\n",
    "    stations_filtered['radar_stn_distance_dict'] = stations_filtered.apply(lambda row: calculate_radar_stn_distances(row), axis=1)    \n",
    "    stations_filtered['closest_radar_station'] = stations_filtered.apply(lambda row: find_closest_radar_stn(row), axis=1)\n",
    "    stations_filtered['radar_distance_km'] = stations_filtered.apply(lambda row: find_closest_radar_stn_distance(row), axis=1)\n",
    "    \n",
    "    # radar range is a 240km radius from the station\n",
    "    stations_filtered = stations_filtered[stations_filtered['radar_distance_km'] < 190]\n",
    "    stn_df = stations_filtered[np.isfinite(stations_filtered['DA'].astype(float))]\n",
    "    # filter for stations greater than 10 km^2 (too small for meaningful results)\n",
    "    stn_df = stn_df[stn_df['DA'].astype(float) >= 10]\n",
    "    # filter for stations smaller than 1000 km^2 (too large and complex)\n",
    "    stn_df = stn_df[stn_df['DA'].astype(float) < 1000].sort_values('DA')\n",
    "    df = stn_df[['Province', 'Station Number', 'Station Name', 'DA', \n",
    "                 'Elevation', 'Latitude', 'Longitude', 'RADAR_Overlap',\n",
    "                'closest_radar_station', 'radar_stn_distance_dict', 'radar_distance_km']]\n",
    "#     print('After filtering, there are {} candidate stations.'.format(len(stn_df)))\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_runoff_dataframe(test_stn):\n",
    "    \n",
    "    runoff_df = get_daily_runoff(test_stn)\n",
    "    runoff_df['Year'] = runoff_df.index.year\n",
    "    runoff_df['Month'] = runoff_df.index.month\n",
    "    \n",
    "    # filter by minimum radar date\n",
    "    runoff_df = runoff_df[runoff_df.index > pd.to_datetime('2007-05-31')]\n",
    "    \n",
    "    runoff_df['Date'] = runoff_df.index.values\n",
    "    \n",
    "    return runoff_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_df(df, stn_da):\n",
    "    lag_df = df[['DAILY_FLOW']].copy()\n",
    "    lag_df.rename(columns={'DAILY_FLOW': 'Q'}, inplace=True)\n",
    "\n",
    "    num_lags = int(np.ceil(stn_da / 100) + 5)\n",
    "\n",
    "    for i in range(1,num_lags):\n",
    "        lag_df['Q{}'.format(i)] = lag_df['Q'].shift(i)\n",
    "\n",
    "    lag_df.dropna(inplace=True)\n",
    "    \n",
    "    return lag_df, num_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on code from Anomaly detection ML methods article:\n",
    "# https://towardsdatascience.com/machine-learning-for-anomaly-detection-and-condition-monitoring-d4614e7de770\n",
    "def split_train_and_test_data(data, training_months, training_year):\n",
    "    time_range_check = (data.index.year == training_year[0]) & (data.index.month.isin(list(training_months)[0]))\n",
    "    train_data = data[time_range_check]\n",
    "    # the test data is the entire dataset because we want to extract\n",
    "    # extreme events from the training year as well\n",
    "    test_data = data\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MahalanobisDist(inv_cov_matrix, mean_distr, data, verbose=False):\n",
    "    inv_covariance_matrix = inv_cov_matrix\n",
    "    vars_mean = mean_distr\n",
    "    diff = data - vars_mean\n",
    "    md = []\n",
    "    for i in range(len(diff)):\n",
    "        md.append(np.sqrt(diff[i].dot(inv_covariance_matrix).dot(diff[i])))\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MD_detectOutliers(dist, extreme=False, verbose=False):\n",
    "    k = 3. if extreme else 2.\n",
    "    threshold = np.mean(dist) * k\n",
    "    outliers = []\n",
    "    for i in range(len(dist)):\n",
    "        if dist[i] >= threshold:\n",
    "            outliers.append(i)  # index of the outlier\n",
    "    return np.array(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MD_threshold(dist, extreme=False, verbose=False):\n",
    "    k = 3. if extreme else 2.\n",
    "    threshold = np.mean(dist) * k\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pos_def(A):\n",
    "    if np.allclose(A, A.T):\n",
    "        try:\n",
    "            np.linalg.cholesky(A)\n",
    "            return True\n",
    "        except np.linalg.LinAlgError:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_PCA(X_train, X_test, n_components):\n",
    "    \n",
    "    for n_components_kept in range(2, n_components + 1):\n",
    "\n",
    "        pca = PCA(n_components=n_components_kept, svd_solver= 'full')\n",
    "        X_train_PCA = pca.fit_transform(X_train)\n",
    "        X_train_PCA = pd.DataFrame(X_train_PCA)\n",
    "        X_train_PCA.index = X_train.index\n",
    "\n",
    "        X_test_PCA = pca.transform(X_test)\n",
    "        X_test_PCA = pd.DataFrame(X_test_PCA)\n",
    "        X_test_PCA.index = X_test.index\n",
    "\n",
    "        var_expl = 100*np.sum(pca.explained_variance_ratio_)\n",
    "        if var_expl >= 90:\n",
    "#             print('var > 0.9 in {} components'.format(n_components_kept))\n",
    "            return X_train_PCA, X_test_PCA, var_expl, n_components_kept\n",
    "#     print('var < 0.9 in {} components'.format(n_components_kept))\n",
    "    return X_train_PCA, X_test_PCA, var_expl, n_components_kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_input_data(wsc_stn_num):\n",
    "        \n",
    "    t0 = time.time()\n",
    "    stn_df = initialize_wsc_station_info_dataframe()\n",
    "\n",
    "    test_stn_info = stn_df[stn_df['Station Number'] == wsc_stn_num]\n",
    "    stn_da = test_stn_info['DA'].values[0]\n",
    "    wsc_stn_name = test_stn_info['Station Name'].values[0]\n",
    "    closest_radar_stn = test_stn_info['closest_radar_station'].values[0]\n",
    "#     print('{} ({}) has a DA of {} km^2'.format(wsc_stn_name, wsc_stn_num, stn_da))\n",
    "    \n",
    "    runoff_df = initialize_runoff_dataframe(wsc_stn_num)    \n",
    "    lag_df, num_lags = create_lag_df(runoff_df, stn_da) \n",
    "    \n",
    "    \n",
    "    candidate_stations = stn_df['Station Number'].values\n",
    "    \n",
    "    return lag_df, closest_radar_stn, runoff_df, num_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_array):\n",
    "    \n",
    "    training_months = input_array[0], \n",
    "    training_year = input_array[1],\n",
    "    training_set_len = input_array[2]\n",
    "    wsc_station_num = input_array[3]\n",
    "    training_sample_size = input_array[4]\n",
    "\n",
    "    lag_df, closest_radar_stn, runoff_df, num_lags = initialize_input_data(wsc_station_num)\n",
    "    \n",
    "    dataset_train, dataset_test = split_train_and_test_data(lag_df, training_months, training_year)\n",
    "    \n",
    "    training_set_len = len(dataset_train)\n",
    "    \n",
    "    if len(dataset_train) < 2:\n",
    "        print('exited because dataset_train is too small')\n",
    "#         print(dataset_train)\n",
    "        return pd.DataFrame([]), 0\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(dataset_train), \n",
    "                                  columns=dataset_train.columns, \n",
    "                                  index=dataset_train.index)\n",
    "    # Random shuffle training data\n",
    "    X_train.sample(frac=1)\n",
    "\n",
    "    X_test = pd.DataFrame(scaler.transform(dataset_test), \n",
    "                                 columns=dataset_test.columns, \n",
    "                                 index=dataset_test.index)\n",
    "    \n",
    "   \n",
    "    X_train_PCA, X_test_PCA, var_expl, n_components = do_PCA(X_train, X_test, num_lags)\n",
    "    \n",
    "    data_train = np.array(X_train_PCA.values)\n",
    "    data_test = np.array(X_test_PCA.values)\n",
    "    \n",
    "    def cov_matrix(data, verbose=False):\n",
    "        covariance_matrix = np.cov(data, rowvar=False)\n",
    "        if is_pos_def(covariance_matrix):\n",
    "            inv_covariance_matrix = np.linalg.inv(covariance_matrix)\n",
    "            if is_pos_def(inv_covariance_matrix):\n",
    "                return True, covariance_matrix, inv_covariance_matrix\n",
    "            else:\n",
    "                print(\"Error: Inverse of Covariance Matrix is not positive definite!\")\n",
    "                return False, None, None\n",
    "        else:\n",
    "            print(\"Error: Covariance Matrix is not positive definite!\")\n",
    "            return False, None, None\n",
    "\n",
    "               \n",
    "    cov_test, cov_matrix, inv_cov_matrix = cov_matrix(data_train)\n",
    "    \n",
    "    if cov_test == False:\n",
    "        return pd.DataFrame([]), 0\n",
    "\n",
    "    mean_distr = data_train.mean(axis=0)\n",
    "\n",
    "    dist_test = MahalanobisDist(inv_cov_matrix, mean_distr, data_test, verbose=False)\n",
    "    dist_train = MahalanobisDist(inv_cov_matrix, mean_distr, data_train, verbose=False)\n",
    "    threshold = MD_threshold(dist_train, extreme = True)\n",
    "    \n",
    "    anomaly_train = pd.DataFrame()\n",
    "    anomaly_train['Mob dist']= dist_train\n",
    "    anomaly_train['Thresh'] = threshold\n",
    "    # If Mob dist above threshold: Flag as anomaly\n",
    "    anomaly_train['Anomaly'] = anomaly_train['Mob dist'] > anomaly_train['Thresh']\n",
    "    anomaly_train.index = X_train_PCA.index\n",
    "    anomaly = pd.DataFrame()\n",
    "    anomaly['Mob dist']= dist_test\n",
    "    anomaly['Thresh'] = threshold\n",
    "    anomaly['num_components_kept'] = n_components\n",
    "    # If Mob dist above threshold: Flag as anomaly\n",
    "    anomaly['Anomaly'] = anomaly['Mob dist'] > anomaly['Thresh']\n",
    "    anomaly.index = X_test_PCA.index\n",
    "    anomaly.head()\n",
    "    \n",
    "    anomaly_alldata = pd.concat([anomaly_train, anomaly], sort=True)\n",
    "    \n",
    "    event_times = np.where(anomaly_alldata['Anomaly'].values[:-1] != anomaly_alldata['Anomaly'].values[1:])[0]\n",
    "    events = pd.merge(lag_df, anomaly_alldata.iloc[event_times,:], how='inner', \n",
    "                      left_index=True, right_index=True)\n",
    "\n",
    "    events = events.loc[~events.index.duplicated(keep='first')]\n",
    "    \n",
    "    if len(events) == 0:\n",
    "        print('exited because len(events) == 0')\n",
    "        return pd.DataFrame([]), 0\n",
    "    elif events.iloc[0]['Anomaly'] == True:\n",
    "        events = events.iloc[1:]\n",
    "        \n",
    "    # create a column of time difference between events in days\n",
    "    events['dt_days'] = events.index.to_series().diff(1)    \n",
    "\n",
    "    a = time.time()\n",
    "\n",
    "    last_event_end = False\n",
    "\n",
    "    new_events = pd.DataFrame()\n",
    "\n",
    "    # iterate through the detected event pairs \n",
    "    for i in np.arange(0, len(events) - 1, 2):\n",
    "        # parse a single event pair\n",
    "        this_event = events.iloc[i:i+2]\n",
    "        \n",
    "        check_sign_switch = this_event['Anomaly'].values[0] != this_event['Anomaly'].values[1]\n",
    "        concurrent_wsc = lag_df[(lag_df.index >= this_event.index.values[0]) & (lag_df.index <= this_event.index.values[1])][['Q']]\n",
    "        peak_in_middle = check_peak_in_middle(this_event, concurrent_wsc)\n",
    "\n",
    "        if (check_sign_switch) & (peak_in_middle):\n",
    "\n",
    "            # get the start date\n",
    "            this_event_start = pd.to_datetime(this_event[this_event['Anomaly'] == False].index.values[0])\n",
    "            # get the end date\n",
    "            this_event_end = pd.to_datetime(this_event[this_event['Anomaly'] == True].index.values[0])\n",
    "\n",
    "            new_event_start = lag_df[lag_df.index == this_event_start][['Q']]\n",
    "            new_event_end = lag_df[lag_df.index == this_event_end][['Q']]\n",
    "\n",
    "            adjusted_start_date = pd.to_datetime(adjust_edge_date(this_event_start, lag_df[['Q']], 'start'))\n",
    "\n",
    "            new_event_start = lag_df[lag_df.index == adjusted_start_date][['Q']]\n",
    "\n",
    "            if last_event_end is not False:\n",
    "\n",
    "                # find if the start date is on the rising limb - adjust if so\n",
    "                if adjusted_start_date < last_event_end:\n",
    "                    new_event_start = lag_df[lag_df.index == this_event_start][['Q']]\n",
    "\n",
    "            new_event_start['timing'] = 'start'\n",
    "            new_event_end['timing'] = 'end'\n",
    "\n",
    "            min_time_check = (new_event_end.index - new_event_start.index).days > 1\n",
    "            max_time_check = (new_event_end.index - new_event_start.index).days <= 14\n",
    "            start_month = new_event_start.index.month\n",
    "            end_month = new_event_end.index.month\n",
    "            season_check = (start_month > 5) & (start_month <= 11) & (end_month <= 11)\n",
    "\n",
    "            if (min_time_check) & (max_time_check) & (season_check):\n",
    "                # filter out events that are longer than 5 days\n",
    "                new_events = new_events.append(new_event_start)\n",
    "                new_events = new_events.append(new_event_end)\n",
    "\n",
    "            last_event_end = pd.to_datetime(this_event_end)\n",
    "\n",
    "\n",
    "    b = time.time()\n",
    "#     print(b - a)\n",
    "\n",
    "    new_events.sort_index(inplace=True)\n",
    "    \n",
    "\n",
    "    new_events['dt_days'] = new_events.index.to_series().diff(1)\n",
    "    new_events['wsc_station'] = wsc_station_num\n",
    "    new_events['training_year'] = training_year[0]\n",
    "    new_events['training_months'] = training_months * len(new_events)\n",
    "    new_events['training_set_len'] = training_set_len\n",
    "    new_events['m_threshold'] = threshold\n",
    "    new_events['var_explained'] = var_expl\n",
    "    new_events['n_components'] = n_components\n",
    "    new_events['num_lags'] = num_lags\n",
    "                \n",
    "    return new_events, n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_edge_date(initial_date, data, direction):\n",
    "    \"\"\"\n",
    "    If the start flow is on a rising limb, adjust the start to the start of the runoff event.\n",
    "    \"\"\"\n",
    "    initial_val = data[data.index == initial_date]['Q']\n",
    "\n",
    "    if direction == 'end':\n",
    "        search_criteria = (data.index <= initial_date + pd.Timedelta('7 days')) & (data.index >= initial_date)\n",
    "        search_direction = -1\n",
    "    elif direction == 'start':\n",
    "        search_criteria = (data.index >= initial_date - pd.Timedelta('7 days')) & (data.index <= initial_date)\n",
    "        search_direction = 1\n",
    "        \n",
    "        \n",
    "    extended_week_vals = data[search_criteria][['Q']]\n",
    "    extended_week_vals['diff'] = extended_week_vals.diff(periods=search_direction)\n",
    "    extended_week_vals['pct_change'] = 100 * extended_week_vals['diff'] / extended_week_vals['Q']\n",
    "\n",
    "    if direction == 'start':\n",
    "        try:\n",
    "            extended_week_vals.at[extended_week_vals.index.min(),'diff'] = -1\n",
    "            change_point_row = extended_week_vals[['pct_change']].idxmax()\n",
    "            if len(change_point_row) > 1:\n",
    "                change_point_date = extended_week_vals.loc[change_point_row - pd.DateOffset(1)].index.values[0]\n",
    "                adjusted_date = change_point_date\n",
    "            else:\n",
    "                adjusted_date = initial_date\n",
    "            \n",
    "        except ValueError as err:\n",
    "            adjusted_date = initial_date\n",
    "\n",
    "    elif direction == 'end':\n",
    "        try:\n",
    "            change_point = extended_week_vals[extended_week_vals['diff'] < 0][['Q']].idxmin().values[0]\n",
    "            adjusted_dates = change_point\n",
    "\n",
    "        except ValueError as err:\n",
    "            change_point = extended_week_vals[extended_week_vals['Q'] == extended_week_vals['Q'].min()].index.values[0]\n",
    "            adjusted_date = change_point\n",
    "\n",
    "            \n",
    "    return pd.to_datetime(adjusted_date)\n",
    "\n",
    "\n",
    "def check_peak_in_middle(event, data):\n",
    "    \"\"\"\n",
    "    Ensure there is a peak between the start and end points\n",
    "    so we aren't targeting a non-runoff event.\n",
    "    \"\"\"\n",
    "    start_time = event.index.values[0] \n",
    "    end_time = event.index.values[-1]\n",
    "    max_time = data[data['Q'] == data['Q'].max()].index.values[0]\n",
    "    if (max_time == start_time) | (max_time == end_time):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_all_combinations(months, years):\n",
    "    month_combos = [list(itertools.combinations(months, n)) for n in range(1, len(months) + 1)]\n",
    "    flat_combos =  [item for sublist in month_combos for item in sublist]\n",
    "    return np.asarray(list(itertools.product(flat_combos, years)))\n",
    "\n",
    "\n",
    "def run_AD_training(wsc_station_num, stn_df, runoff_df, radar_stn, training_sample_size=5, ):\n",
    "    \n",
    "    training_months = list(set(runoff_df.index.month))\n",
    "    training_years = list(set(runoff_df.index.year))     \n",
    "\n",
    "    all_combinations = get_all_combinations(training_months, training_years)\n",
    "      \n",
    "    # a complete search is intractable, so sample n permutations without replacement\n",
    "    rand_ints = np.random.choice(range(len(all_combinations)), training_sample_size, replace=False)\n",
    "\n",
    "    sample_list = all_combinations[rand_ints]\n",
    "    \n",
    "    input_array = [[*c, training_sample_size, wsc_station_num, radar_stn] for c in sample_list]\n",
    "    \n",
    "    results = [(i, *train_model(i)) for i in input_array]\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 141: 08HB048: 38.37s\n",
      "2 of 141: 08LF100: 25.35s\n",
      "3 of 141: 08NM146: 24.07s\n",
      "4 of 141: 08HA016: 37.80s\n",
      "5 of 141: 08LE108: 26.53s\n",
      "6 of 141: 05CD913: 23.67s\n",
      "7 of 141: 08LE077: 28.15s\n",
      "8 of 141: 08NJ061: 30.21s\n",
      "9 of 141: 08HA070: 37.49s\n",
      "10 of 141: 08NN028: 26.66s\n",
      "11 of 141: 05BM018: 27.27s\n",
      "12 of 141: 08NM134: 25.91s\n",
      "exited because dataset_train is too small\n",
      "exited because dataset_train is too small\n",
      "exited because dataset_train is too small\n",
      "13 of 141: 05BH013: 23.97s\n",
      "14 of 141: 08MH006: 39.20s\n",
      "15 of 141: 08NM173: 27.92s\n",
      "16 of 141: 05CE010: 29.78s\n",
      "17 of 141: 08NJ168: 27.63s\n",
      "18 of 141: 08MH076: 31.60s\n",
      "19 of 141: 08LF099: 24.35s\n",
      "20 of 141: 08MH141: 34.91s\n",
      "21 of 141: 08NJ026: 29.97s\n",
      "exited because len(events) == 0\n",
      "exited because len(events) == 0\n",
      "exited because dataset_train is too small\n",
      "exited because len(events) == 0\n",
      "22 of 141: 08LB012: 21.52s\n",
      "23 of 141: 08NE114: 29.61s\n",
      "24 of 141: 05CC010: 26.10s\n",
      "25 of 141: 05CE011: 29.21s\n",
      "26 of 141: 08NM142: 25.27s\n",
      "27 of 141: 08GA077: 34.88s\n",
      "28 of 141: 05AB040: 32.70s\n",
      "29 of 141: 08MH155: 37.65s\n",
      "30 of 141: 08LC040: 30.71s\n",
      "exited because dataset_train is too small\n",
      "31 of 141: 05AA909: 28.87s\n",
      "Error: Covariance Matrix is not positive definite!\n",
      "32 of 141: 05FC007: 26.82s\n",
      "33 of 141: 08LG056: 26.35s\n",
      "34 of 141: 05FA014: 27.03s\n",
      "35 of 141: 08LA028: 26.55s\n",
      "36 of 141: 08NE087: 32.29s\n",
      "37 of 141: 08GA079: 33.00s\n",
      "38 of 141: 08MF062: 30.64s\n",
      "39 of 141: 08HB032: 30.53s\n",
      "40 of 141: 08LG016: 26.73s\n",
      "41 of 141: 08MG026: 26.68s\n",
      "42 of 141: 08NH132: 30.76s\n",
      "43 of 141: 08NE008: 28.64s\n",
      "exited because len(events) == 0\n",
      "44 of 141: 08LF094: 25.58s\n",
      "45 of 141: 08MC045: 24.84s\n",
      "46 of 141: 08KB006: 29.71s\n",
      "exited because len(events) == 0\n",
      "47 of 141: 08HB024: 24.97s\n",
      "48 of 141: 08NM174: 26.20s\n",
      "49 of 141: 08NM171: 27.57s\n",
      "50 of 141: 05CG006: 26.95s\n",
      "51 of 141: 08KE024: 29.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n",
      "52 of 141: 05AB029: 28.76s\n",
      "53 of 141: 08LB024: 25.61s\n",
      "54 of 141: 08GB014: 32.46s\n",
      "exited because dataset_train is too small\n",
      "55 of 141: 05BL027: 25.45s\n",
      "56 of 141: 08NK022: 28.32s\n",
      "57 of 141: 08MH029: 35.81s\n",
      "58 of 141: 08NN019: 30.45s\n",
      "59 of 141: 08GB013: 32.73s\n",
      "60 of 141: 08MH056: 32.44s\n",
      "61 of 141: 08HB014: 38.55s\n",
      "62 of 141: 05CD006: 29.67s\n",
      "63 of 141: 08LB076: 30.92s\n",
      "64 of 141: 05BL022: 28.83s\n",
      "exited because dataset_train is too small\n",
      "exited because dataset_train is too small\n",
      "exited because dataset_train is too small\n",
      "65 of 141: 08LG068: 27.94s\n",
      "exited because len(events) == 0\n",
      "66 of 141: 08NJ160: 29.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n",
      "67 of 141: 05FC004: 25.57s\n",
      "68 of 141: 05CE018: 31.90s\n",
      "69 of 141: 05CG004: 27.37s\n",
      "70 of 141: 08NE077: 29.71s\n",
      "exited because dataset_train is too small\n",
      "71 of 141: 05DB005: 26.51s\n",
      "72 of 141: 08HA003: 35.50s\n",
      "73 of 141: 08HB074: 30.99s\n",
      "74 of 141: 05AD035: 27.84s\n",
      "75 of 141: 05AA027: 26.35s\n",
      "76 of 141: 08NN023: 28.48s\n",
      "77 of 141: 05BL023: 26.31s\n",
      "78 of 141: 08NN015: 27.78s\n",
      "79 of 141: 05CA011: 26.23s\n",
      "exited because dataset_train is too small\n",
      "80 of 141: 05CC009: 26.83s\n",
      "exited because dataset_train is too small\n",
      "81 of 141: 05BH014: 25.10s\n",
      "82 of 141: 08KA009: 29.41s\n",
      "83 of 141: 08NL071: 27.82s\n",
      "84 of 141: 05AB013: 24.98s\n",
      "85 of 141: 05BK001: 27.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n",
      "86 of 141: 05FC002: 22.97s\n",
      "87 of 141: 08GA075: 28.55s\n",
      "88 of 141: 08MH147: 28.38s\n",
      "exited because len(events) == 0\n",
      "exited because len(events) == 0\n",
      "Error: Covariance Matrix is not positive definite!\n",
      "exited because len(events) == 0\n",
      "exited because dataset_train is too small\n",
      "Error: Covariance Matrix is not positive definite!\n",
      "89 of 141: 08NM246: 20.64s\n",
      "90 of 141: 08GA072: 27.78s\n",
      "91 of 141: 08NE110: 26.30s\n",
      "92 of 141: 07EE009: 25.08s\n",
      "93 of 141: 08ME027: 27.91s\n",
      "94 of 141: 08LG048: 28.23s\n",
      "95 of 141: 08HB002: 35.68s\n",
      "exited because len(events) == 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n",
      "exited because dataset_train is too small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/danbot/Documents/code/cuda_env/lib/python3.6/site-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Covariance Matrix is not positive definite!\n",
      "96 of 141: 05CK007: 20.64s\n",
      "97 of 141: 08NE006: 27.13s\n",
      "98 of 141: 05BG006: 29.28s\n",
      "99 of 141: 08MH016: 29.72s\n",
      "100 of 141: 08NE039: 28.18s\n",
      "101 of 141: 05AC030: 26.24s\n",
      "102 of 141: 05CC008: 27.34s\n",
      "103 of 141: 08HA001: 35.07s\n",
      "exited because len(events) == 0\n",
      "104 of 141: 08MG001: 29.87s\n",
      "105 of 141: 08NL050: 26.08s\n",
      "106 of 141: 08NL070: 26.77s\n",
      "107 of 141: 08KA001: 27.76s\n",
      "108 of 141: 08NF001: 29.74s\n",
      "109 of 141: 08JE004: 26.43s\n",
      "110 of 141: 05AB005: 26.42s\n",
      "111 of 141: 08NH005: 29.21s\n",
      "112 of 141: 05CB002: 31.70s\n",
      "113 of 141: 07FB009: 31.55s\n",
      "114 of 141: 05CC011: 29.40s\n",
      "115 of 141: 05CA012: 27.37s\n",
      "116 of 141: 05CE012: 23.18s\n",
      "117 of 141: 05BL013: 28.62s\n",
      "118 of 141: 05CD007: 28.17s\n",
      "119 of 141: 08NL069: 28.79s\n",
      "120 of 141: 08HA010: 36.23s\n",
      "121 of 141: 08NH130: 31.20s\n",
      "122 of 141: 05BL014: 31.90s\n",
      "123 of 141: 08NK018: 29.39s\n",
      "124 of 141: 08LB069: 30.17s\n",
      "125 of 141: 05CB004: 33.99s\n",
      "exited because len(events) == 0\n",
      "126 of 141: 08MH103: 28.53s\n",
      "127 of 141: 05CK001: 26.61s\n",
      "128 of 141: 08MF065: 28.23s\n",
      "129 of 141: 08MF068: 28.53s\n",
      "130 of 141: 05CE006: 28.20s\n",
      "131 of 141: 05BL019: 26.45s\n",
      "132 of 141: 08LG008: 25.36s\n",
      "133 of 141: 05BM014: 26.23s\n",
      "134 of 141: 05BJ004: 27.81s\n",
      "135 of 141: 05CC013: 24.39s\n",
      "136 of 141: 08LE027: 31.01s\n",
      "137 of 141: 05CA002: 26.71s\n",
      "138 of 141: 05DB002: 28.92s\n",
      "139 of 141: 08LE024: 29.95s\n",
      "140 of 141: 08ND012: 29.53s\n",
      "141 of 141: 05CA004: 25.62s\n",
      "For n=30, execution time = 4151.937625408173\n"
     ]
    }
   ],
   "source": [
    "stn_df = initialize_wsc_station_info_dataframe()\n",
    "\n",
    "all_wsc_stations = stn_df['Station Number'].values\n",
    "\n",
    "for s_size in [30]:\n",
    "    sample_path = os.path.join(PROJECT_DIR, 'data/AD_results/sample_{}/'.format(s_size))\n",
    "    \n",
    "    if not os.path.exists(sample_path):\n",
    "        os.makedirs(sample_path)\n",
    "    \n",
    "    ta = time.time()\n",
    "    \n",
    "    n = 0\n",
    "    \n",
    "    for wsc_stn in all_wsc_stations:\n",
    "        \n",
    "        stn_df = initialize_wsc_station_info_dataframe()    \n",
    "        radar_stn = stn_df[stn_df['Station Number'] == wsc_stn]['closest_radar_station'].values[0]\n",
    "        runoff_df = initialize_runoff_dataframe(wsc_stn)       \n",
    "\n",
    "        n += 1\n",
    "        t0 = time.time()\n",
    "        results = run_AD_training(wsc_stn, stn_df, runoff_df, radar_stn, s_size)\n",
    "        t1 = time.time()\n",
    "        print('{} of {}: {}: {:.2f}s'.format(n, len(all_wsc_stations), wsc_stn, t1 - t0))\n",
    "\n",
    "        AD_model_params = []\n",
    "        for r in results:\n",
    "            params = r[0]\n",
    "            result_info = r[1]\n",
    "            n_components = r[2]\n",
    "#             print(params, len(result_info), num_lags)\n",
    "            months = params[0]\n",
    "            year = params[1]\n",
    "            n_sample = params[2]\n",
    "            AD_model_params.append((months, year, wsc_stn, radar_stn, n_sample, len(result_info), n_components))\n",
    "\n",
    "        result_df = pd.DataFrame(AD_model_params, columns=['train_months', 'train_year', 'wsc_stn', 'radar_stn', 'n_sample', 'len_results', 'num_components'])\n",
    "        results_save_path = os.path.join(PROJECT_DIR, 'data/AD_results/sample_{}/{}_results.csv'.format(n_sample, wsc_stn))\n",
    "        result_df.to_csv(results_save_path)\n",
    "        \n",
    "    tb = time.time()\n",
    "    print('For n={}, execution time = {}'.format(s_size, tb-ta))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  End of Find Events Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width=800, plot_height=400, x_axis_type='datetime')\n",
    "\n",
    "e1 = best_events[best_events['timing'] == 'start']\n",
    "e2 = best_events[best_events['timing'] == 'end']\n",
    "\n",
    "p.circle(e1.index, e1['Q'], color='red', alpha=0.5, size=10, legend_label='start')\n",
    "p.circle(e2.index, e2['Q'], color='blue', alpha=0.5, size=10, legend_label='end')\n",
    "\n",
    "# p.line(input_sig.index, input_sig['f_sig'], color='blue')\n",
    "p.line(input_sig.index, input_sig['DAILY_FLOW'], color='blue')\n",
    "# p.line()\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid plot of individual events\n",
    "\n",
    "plots = []\n",
    "\n",
    "for i in np.arange(0, len(best_events) - 1, 2):\n",
    "    \n",
    "    # parse a single event pair\n",
    "    this_event = best_events.iloc[i:i+2]\n",
    "    \n",
    "    s1 = figure(background_fill_color=\"#fafafa\", x_axis_type='datetime')\n",
    "    \n",
    "    s1.circle(this_event.index, this_event['Q'], \n",
    "              size=12, alpha=0.8, color=\"red\")#, legend_label='{estimated endpoints}')\n",
    "    s1.xaxis.major_label_orientation = math.pi/2\n",
    "    this_start = pd.to_datetime(this_event.index.values[0])\n",
    "    this_end = pd.to_datetime(this_event.index.values[1])\n",
    "    this_dat = lag_df[(lag_df.index >= this_start) & (lag_df.index <= this_end)][['Q']]\n",
    "    \n",
    "    if (this_end.month < 12) & (this_start.month > 5):\n",
    "        year = this_event.index.year.values[0]\n",
    "        month = this_event.index.month.values[0]\n",
    "        day = this_event.index.day.values[0]\n",
    "        date = '{}-{}-{}'.format(year, month, day)\n",
    "        s1.line(this_dat.index, this_dat['Q'], color='blue')\n",
    "        plots.append(s1)\n",
    "\n",
    "print('there are {} plots'.format(len(plots)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(plots) < 6:\n",
    "#     grid = gridplot(plots, plot_width=150, plot_height=150)\n",
    "# else:\n",
    "n_cols = 5\n",
    "n_rows = int(np.ceil(len(plots) / n_cols))\n",
    "\n",
    "g = []\n",
    "for i in range(0, len(plots), n_cols):\n",
    "    g += [plots[i:i+n_cols]]\n",
    "grid = gridplot(g, plot_width=150, plot_height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_pairs = []\n",
    "for i in np.arange(0, len(best_events) - 1, 2):\n",
    "    # parse a single event pair\n",
    "    this_event = best_events.iloc[i:i+2]\n",
    "    date_pair = [e.astype(str).replace('T', ' ').split('.')[0].split(' ')[0] for e in this_event.index.values]\n",
    "    this_start = pd.to_datetime(this_event.index.values[0])\n",
    "    this_month = this_start.month\n",
    "    if (this_month > 5) & (this_month <= 11) & (this_start > pd.to_datetime('2007-01-01')):\n",
    "        event_pairs.append(date_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Stn {}: {}'.format(test_stn, test_stn_info['Station Name'].values[0]))\n",
    "print('There are {} events that meet the criteria.'.format(len(event_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop winter events and group for individual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width=800, plot_height=400, x_axis_type='datetime')\n",
    "\n",
    "# p.circle(adj_starts.index, adj_starts['Q'], size=10, color=\"red\", \n",
    "#          alpha=0.5, legend_label='start'.format(len(foo)))\n",
    "# p.circle(adj_ends.index, adj_ends['Q'], size=10, color=\"blue\", \n",
    "#          alpha=0.5, legend_label='end'.format(len(foo)))\n",
    "\n",
    "p.circle(starts.index, starts['DAILY_FLOW'], size=10, color=\"red\", \n",
    "         alpha=0.5, legend_label='start'.format(len(foo)))\n",
    "p.circle(ends.index, ends['DAILY_FLOW'], size=10, color=\"blue\", \n",
    "         alpha=0.5, legend_label='end'.format(len(foo)))\n",
    "# p.line(input_sig.index, input_sig['f_sig'], color='blue')\n",
    "p.line(input_sig.index, input_sig['DAILY_FLOW'], color='blue')\n",
    "# p.line()\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Autoencoder Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(10)\n",
    "tensorflow.random.set_seed(10)\n",
    "act_func = 'elu'\n",
    "\n",
    "# Input layer:\n",
    "model=Sequential()\n",
    "# First hidden layer, connected to input vector X. \n",
    "model.add(Dense(10,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_shape=(X_train.shape[1],)\n",
    "               )\n",
    "         )\n",
    "\n",
    "model.add(Dense(2,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(10,activation=act_func,\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=100\n",
    "BATCH_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(np.array(X_train),np.array(X_train),\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.05,\n",
    "                  verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],\n",
    "         'b',\n",
    "         label='Training loss')\n",
    "plt.plot(history.history['val_loss'],\n",
    "         'r',\n",
    "         label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss, [mse]')\n",
    "plt.ylim([0,.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_train))\n",
    "X_pred = pd.DataFrame(X_pred, \n",
    "                      columns=X_train.columns)\n",
    "X_pred.index = X_train.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_train.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_train), axis = 1)\n",
    "plt.figure()\n",
    "sns.distplot(scored['Loss_mae'],\n",
    "             bins = 10, \n",
    "             kde= True,\n",
    "            color = 'blue');\n",
    "plt.xlim([0.0,.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_test))\n",
    "X_pred = pd.DataFrame(X_pred, \n",
    "                      columns=X_test.columns)\n",
    "X_pred.index = X_test.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_test.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)\n",
    "scored['Threshold'] = 0.3\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_train = model.predict(np.array(X_train))\n",
    "X_pred_train = pd.DataFrame(X_pred_train, \n",
    "                      columns=X_train.columns)\n",
    "X_pred_train.index = X_train.index\n",
    "\n",
    "scored_train = pd.DataFrame(index=X_train.index)\n",
    "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)\n",
    "scored_train['Threshold'] = 0.3\n",
    "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
    "scored = pd.concat([scored_train, scored], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored[scored.index > pd.to_datetime('2016-06-01')].plot(logy=True,  figsize = (10,6), ylim = [1e-2,1e2], color = ['blue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_times = np.where(scored['Anomaly'].values[:-1] != scored['Anomaly'].values[1:])[0]\n",
    "events = pd.merge(input_sig, scored.iloc[event_times,:], how='inner', \n",
    "                  left_index=True, right_index=True)\n",
    "\n",
    "starts = events[events['Anomaly'] == False]\n",
    "ends = events[events['Anomaly'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(plot_width=800, plot_height=400, x_axis_type='datetime')\n",
    "\n",
    "# p.circle(adj_starts.index, adj_starts['Q'], size=10, color=\"red\", \n",
    "#          alpha=0.5, legend_label='start'.format(len(foo)))\n",
    "# p.circle(adj_ends.index, adj_ends['Q'], size=10, color=\"blue\", \n",
    "#          alpha=0.5, legend_label='end'.format(len(foo)))\n",
    "\n",
    "p.circle(starts.index, starts['DAILY_FLOW'], size=10, color=\"red\", \n",
    "         alpha=0.5, legend_label='start'.format(len(foo)))\n",
    "p.circle(ends.index, ends['DAILY_FLOW'], size=10, color=\"blue\", \n",
    "         alpha=0.5, legend_label='end'.format(len(foo)))\n",
    "# p.line(input_sig.index, input_sig['f_sig'], color='blue')\n",
    "p.line(input_sig.index, input_sig['DAILY_FLOW'], color='blue')\n",
    "# p.line()\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates_covered = []\n",
    "# fldr = os.path.join(IMG_DIR, test_stn)\n",
    "# for f in os.listdir(fldr):\n",
    "#     date = f[:4] + '-' + f[4:6] + '-' + f[6:8]\n",
    "#     dates_covered.append(date)\n",
    "\n",
    "# dates_covered = list(set(dates_covered))\n",
    "# unchecked = []\n",
    "# for ep in event_pairs:\n",
    "#     if (ep[0] not in dates_covered) & (ep[1] not in dates_covered):\n",
    "#         unchecked.append(ep)\n",
    "        \n",
    "# print(unchecked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks(data, lag=7, threshold=500, influence=0.5):\n",
    "    # Settings (the ones below are examples: choose what is best for your data)\n",
    "#     lag = 5         # lag 5 for the smoothing functions\n",
    "#     threshold = 3.5  # 3.5 standard deviations for signal\n",
    "#     influence = 0.5  # between 0 and 1, where 1 is normal influence, 0.5 is half\n",
    "    # Initialize variables\n",
    "    signals = np.zeros(len(data))            # Initialize signal results\n",
    "    filteredY = np.empty(len(data))\n",
    "    filteredY[:lag] = data[:lag]             # Initialize filtered series\n",
    "    avgFilter = [0]                          # Initialize average filter\n",
    "    stdFilter = [0]                          # Initialize std. filter\n",
    "    avgFilter = {lag: np.mean(data[:lag])}      # Initialize first value\n",
    "    stdFilter = {lag: np.std(data[:lag])}     # Initialize first value\n",
    "    \n",
    "    for i in range(lag + 1, len(data)):\n",
    "        d = data[i]\n",
    "        \n",
    "        af = avgFilter[i-1]\n",
    "        sf = stdFilter[i-1]\n",
    "        \n",
    "        if abs(d - af) > threshold * sf:\n",
    "            if d > af:\n",
    "                signals[i] = 1                     # Positive signal\n",
    "            else:\n",
    "                signals[i] = -1                    # Negative signal\n",
    "\n",
    "            \n",
    "            filteredY[i] = influence*d + (1-influence)*filteredY[i-1]\n",
    "        else:\n",
    "            signals[i] = 0                        # No signal\n",
    "            filteredY[i] = 0\n",
    "        \n",
    "        \n",
    "        # Adjust the filters\n",
    "        avgFilter[i] = np.mean(filteredY[i-lag:i])\n",
    "        stdFilter[i] = np.std(filteredY[i-lag:i])\n",
    "        \n",
    "    return signals, filteredY\n",
    "\n",
    "n_test = 500\n",
    "\n",
    "dats = list(df['DAILY_FLOW'].to_numpy())\n",
    "sigs, f_dat = find_peaks(dats, influence=0.75, lag=7, threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show, output_notebook\n",
    "\n",
    "input_sig = df[['DAILY_FLOW']].copy()\n",
    "signal = np.array(sigs)\n",
    "input_sig['sig'] = signal.copy().astype(int)\n",
    "input_sig['f_sig'] = f_dat\n",
    "\n",
    "foo = input_sig[input_sig['sig'] == 1].copy()\n",
    "p = figure(plot_width=800, plot_height=400, x_axis_type='datetime')\n",
    "# add a circle renderer with a size, color, and alpha\n",
    "p.circle(foo.index, foo['DAILY_FLOW'], size=10, color=\"red\", \n",
    "         alpha=0.5, legend_label='{} pts'.format(len(foo)))\n",
    "# p.line(input_sig.index, input_sig['f_sig'], color='blue')\n",
    "p.line(input_sig.index, input_sig['DAILY_FLOW'], color='blue')\n",
    "# p.line()\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the summer baseflow\n",
    "\n",
    "Break up the May to November records by periods where it comes back to within X% of baseflow.  \n",
    "\n",
    "check durations of these periods, see how many there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
